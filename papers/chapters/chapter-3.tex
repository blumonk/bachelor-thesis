\chapter{Реализация и экспериментальное исследование}
\section{Реализация алгоритма}
Алгоритм был реализован на языке программирования Java с использованием фреймворка Fork/Join, который хорошо подходит для параллельного исполнения рекурсивных задач.

\subsection{Используемые алгоритмы и структуры данных}
Входной двумерный массив точек остается неизменным, все операции перестановок и модификаций осуществляются на массивах индексов, чтобы избежать лишних копирований памяти.

Для нахождения медианного значения заданного критерия по всем входным точкам используется алгоритм <<Median of medians>> с линейным временем работы.

Большинство процедур в алгоритме изменяют порядок элементов во входном массиве индексов, в связи с чем в параллельной версии возникает задача изолирования памяти.

При каждом вызове \textsc{NDHelperB} копируется нужный отрезок входного массива индексов.
Для восстановления лексикографического порядка во входном массиве используется операция \textsc{merge}.
Операции \textsc{split}, \textsc{merge} и поиск медианы требуют $O(N)$ дополнительной памяти, поэтому они выполняются на буферах, локальных для каждого потока.

Для поддержания упорядоченных множеств <<ступеней>> Парето-фронтов в \textsc{SweepA} и \textsc{SweepB}, описанных в алгоритме Фортена, были реализованы специализированные красно-черное дерево и дерево Фенвика.

Начальная лексикографическая сортировка точек осуществляется с помощью сортировки слиянием.
По мере выполнения лексикографической сортировки заполняется вспомогательный массив $eqComp$ со следующим свойством: если точка $S_i$ совпадает в каждой координате с точкой $S_j$, то $eqComp[i] = eqComp[j]$, если $S_i$ лексикографически меньше $S_j$, то $eqComp[i] < eqComp[j]$.
Эта структура позволяет в дальнейшем сравнивать точки за $O(1)$.

\subsubsection{\textsc{NDHelperA}}
Для реализации описанной во второй главе модификации процедуры \textsc{NDHelperA} необходимо ввести дополнительную структуру, представляющую контекст для отложенного исполнения \textsc{NDHelperB}.

\begin{lstlisting}[float=!h,caption={Вспомогательная структура <<контекст>> для \textsc{NDHelperA}}]
class Context {
    int k;
    int[] compareWith;
    List<Future> futures;
    ...
}
\end{lstlisting}

Добавим в \textsc{NDHelperA} дополнительный аргумент --- список контекстов для отложенного исполнения \textsc{NDHelperB}.

В каждом таком контексте будет храниться:
\begin{itemize}
    \item размерность $k$, по которой будет производиться сравнение;
    \item список индексов $compareWith$ --- точки, с которыми необходимо сравниться;
    \item список $futures$, в который необходимо положить результат отложенного вычисления \textsc{NDHelperB};
\end{itemize}

Если входящий список контекстов не пуст, то до завершения работы \textsc{NDHelperA} необходимо асинхронно запустить выполнение \textsc{NDHelperB} на каждой из частей $L$, $M$ и $H$ в паре с точками из каждого контекста, или на входном отрезке целиком, если деление на части не выполняется.

Результат отложенного исполнения необходимо положить в список $futures$, чтобы у нас была возможность дождаться завершения работы в необходимой нам точке.

В \textsc{NDHelperA(L)} помимо контекстов, переданных сверху, добавляется два новых контекста: первый с отрезком $M$ и списком $waitM$, второй --- с отрезком $H$ и списком $waitH$.
В \textsc{NDHelperA(M)} добавляется контекст с $H$ и списком $waitH$.
Перед запуском \textsc{NDHelperA(M)} мы должны дождаться выполнения задач в $waitM$, а перед запуском \textsc{NDHelperA(H)} --- задач в $waitH$.
Таким образом, все требуемые сравнения точек будут завершены к нужному моменту.

\subsection{Переключение на последовательную версию}
Каждый параллельный вызов \textsc{NDHelperB} при использовании $Fork/Join$ влечет за собой накладные расходы, потому что нам нужно создать новый объект для каждой подзадачи, а также скопировать необходимые отрезки индексов.
Поэтому при достаточно маленьких размерах входных массивов имеет смысл запускать однопоточную версию процедуры.

Был проведен ряд экспериментов при $N=\{10^4, 5\cdot10^4, 10^5\}$, $M=\{3,4,\ldots,15\}$.
В качестве порога в \textsc{NDHelperB} рассматривались степени двойки от $4$ до $1024$.

Лучшие результаты были достигнуты при пороге равном $32$.
Таким образом, если $|L| < 32$ или $|H| < 32$, то запускается однопоточная версия \textsc{NDHelperB(L, H, k)}.

\section{Экспериментальное исследование алгоритма}
Далее будут представлены результаты экспериментального исследования эффективности предложенного алгоритма.

Эксперименты проводились на компьютере с шестнадцатиядерным процессором \textit{AMD Opteron(tm) Processor 6380} с частотой 2.5 ГГц и 4 Гб оперативной памяти.

В качестве тестовых данных использовались искусственно сгенерированные массивы случайных значений. 

Каждая версия алгоритма тестировалась на одной конфигурации входных данных и фиксированном числе потоков исполнения по 25 раз, далее сравнивались минимальное, максимальное и медианное время работы.

\input{chapters/experiments.tex}

\subsection{Оптимизация сортировки}
\subsubsection{Поиск медианы}
Довольно часто вызываемая в данном алгоритме процедура поиска медианы использует в цикле генератор случайных чисел для поиска опорного значения.

Класс $Random$ в языке $Java$ является потоково-безопасным, однако в случае, когда одну и ту же сущность генератора случайных чисел использует сразу несколько потоков исполнения, происходит значительное ухудшение производительности, т.к. потоки делят между собой один ключ внутреннего состояния генератора.

Замена сущности класса $Random$ классом $ThreadLocalRandom$ привела к существенному улучшению экспериментальных результатов алгоритма.

\subsubsection{Уменьшение количества подзадач}
Также большой проблемой на практике является вычислительная стоимость создания новых рекурсивных задач и копирования массивов индексов.

Оптимизация, касающаяся порога переключения \textsc{NDHelperB} на однопоточную версию была описана ранее.

Тем не менее, в процедуре \textsc{NDHelperA} по-прежнему создавались лишние объекты и происходили ненужные копирования памяти при вызове подзадач.
Во избежание подобных накладных расходов часть логики процедуры \textsc{NDHelperB} была продублирована в теле процедуры \textsc{NDHelperA}, а именно, проверка мощностей множеств $L$ и $H$, а также текущей размерности $k$.

Также заметим, что довольно часто среднее подмножество $M$ в \textsc{NDHelperA} и \textsc{NDHelperB}, в которое входят точки с опорным медианным значением, состоит из одного или нескольких элементов. 

В таком случае мы также можем уменьшить количество лишних копирований и создания объектов задач, прикрепив среднее подмножество к меньшему из $L$ и $H$ и продолжить исполнение по схеме алгоритма Фортена.

Вышеописанные оптимизации позволили избавиться от большого количества ненужных дорогостоящих операций.
Таким образом удалось устранить разрыв с оригинальным алгоритмом при малых $M$ и в целом заметно улучшить время работы алгоритма.

\subsubsection{Улучшение SweepA и SweepB}
Изначально для поддержания множеств <<ступеней>> недоминирующих фронтов было реализовано дерево Фенвика.

Встроенный в стандартную библиотеку $TreeMap$ продемонстрировал не самые лучшие результаты из-за накладных расходов при автоупаковке примитивных типов.

В качестве эксперимента было реализовано специализированное красно-черное дерево, заточенное под необходимые нам типы данных.

Применение новой оптимизированной структуры данных также привело к небольшому ускорению работы алгоритма.

\begin{table}[h!]
    \caption{Сравнение структур данных, используемых в \textsc{SweepA} и \textsc{SweepB}. $N=6\cdot10^4$, $4$ потока}
\centering
\begin{tabu}{|*{7}{c|}}
\hline
 & \multicolumn{3}{c|}{Дерево Фенвика} & \multicolumn{3}{c|}{Красно-черное дерево}\\
\cline{2-7}
    M & min & max & med & min & max & med \\
\hline
    3 & 2.33e+02 & 2.39e+02 & 2.34e+02 & 2.27e+02 & 2.31e+02 & 2.28e+02 \\ 
    4 & 5.79e+02 & 6.24e+02 & 5.99e+02 & 5.29e+02 & 5.79e+02 & 5.50e+02 \\
    5 & 1.18e+03 & 1.33e+03 & 1.28e+03 & 1.15e+03 & 1.68e+03 & 1.17e+03 \\
    6 & 2.01e+03 & 2.12e+03 & 2.05e+03 & 1.97e+03 & 2.09e+03 & 2.00e+03 \\
    7 & 2.88e+03 & 3.48e+03 & 2.97e+03 & 2.82e+03 & 3.18e+03 & 2.90e+03 \\
    8 & 3.67e+03 & 3.80e+03 & 3.73e+03 & 3.64e+03 & 3.73e+03 & 3.68e+03 \\
    9 & 4.28e+03 & 4.39e+03 & 4.36e+03 & 4.20e+03 & 4.33e+03 & 4.29e+03 \\
    10& 4.49e+03 & 4.70e+03 & 4.55e+03 & 4.32e+03 & 4.54e+03 & 4.42e+03 \\
\hline
\end{tabu}
\end{table}

\subsection{Анализ модификации NDHelperA}
Несмотря на доказанную теоретическую эффективность, на практике преобразование процедуры \textsc{NDHelperA} имеет довольно узкую область применения.

Это связано с относительно небольшим количеством процессоров, на которых проводилось тестирование.

Как уже было замечено во второй главе, при больших $N$ и начиная с определенной размерности $M$, вызовы \textsc{NDHelperB} производят достаточное количество подзадач, чтобы загрузить работой все свободные процессоры, поэтому предлагаемая модификация \textsc{NDHelperA} не имеет смысла и негативно сказывается на общем времени работы сортировки.

Тем не менее, нам удалось продемонстрировать улучшение времени работы алгоритма при использовании асинхронных вызовов на 32 потоках исполнения при малых $M = \{3,4,5\}$.

Предполагается, что с увеличением количества процессоров мы сможем улучшить степень параллельности алгоритма для малых $M$ и $N$.

\begin{table}[h!]
    \caption{Ускорение при модификации \textsc{NDHelperA}, $N=10^5$}
\centering
\begin{tabu}{|*{7}{c|}}
\hline
 & \multicolumn{3}{c|}{Асинхронная версия} & \multicolumn{3}{c|}{Последовательная версия}\\
\cline{2-7}
    M & min & max & med & min & max & med \\
\hline
    3 & 3.98e+02 & 4.09e+02 & 4.05e+02 & 4.44e+02 & 4.46e+02 & 4.45e+02 \\ 
    4 & 1.26e+03 & 1.38e+03 & 1.33e+03 & 1.35e+03 & 1.47e+03 & 1.42e+03 \\
    5 & 1.61e+03 & 1.86e+03 & 1.75e+03 & 1.87e+03 & 2.04e+03 & 1.95e+03\\
\hline
\end{tabu}
\end{table}

\section{Выводы по главе}
В данной главе были описаны детали реализации, а также проведено экспериментальное исследование предлагаемого алгоритма.

По его результатам можно заключить, что предложенный алгоритм обладает неплохой степенью параллельности и демонстрирует хорошее время работы при различных размерах входных данных.
